{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svm-vs-random-forest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNMuqddzYXTHByTPZTdMEAb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaankoken/random_forest_vs_svm/blob/master/svm_vs_random_forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg4M_-pdnrU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics, datasets, preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5BxtS_BsRd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def randomOneHoldout(X_train, Y_train):\n",
        "    x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)\n",
        "    return x_train, x_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq2gMR9GsPZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stratifiedOneHoldout(X_train, Y_train):\n",
        "    x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)\n",
        "    return x_train, x_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h-TRIWjjJK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visulize_class(df):\n",
        "\t# look at the last column on data frame (the classification value column)\n",
        "\tdf.iloc[:, -1].value_counts().plot(kind='bar')\n",
        "\tplt.title(\"Output Distribution: Breast Cancer DS\")\n",
        "\tplt.xlabel(\"Classification\")\n",
        "\tplt.ylabel(\"Frequency\")\n",
        "\tplt.show()\t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p20yzHFGkiGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def identify_noise(df):\n",
        "\n",
        "\tnoise = df[df.isnull().any(axis=1)].count()\n",
        "\ttotal_noise = noise.sum()\n",
        "\tprint(\"{0} null values were found.\".format(str(total_noise)))\n",
        "\tif(total_noise > 0):\t\n",
        "\t\tprint(noise)\n",
        "\tprint(\"\\n\\nShowing all data types:\\n\\n\")\n",
        "\tprint(df.dtypes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIh5ji52lDrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def heat_map(df):\n",
        "\tfig, ax = plt.subplots()\n",
        "\tcorr = df.corr()\n",
        "\tsns.heatmap(corr, annot=True, cmap='hot')\n",
        "\tplt.show()\t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhyvBA79neK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filter_features(data, bad_indices):\n",
        "\t# eliminate above column indices from the data and return new set\n",
        "\tfiltered_data = np.delete(data, bad_indices, axis=1)\n",
        "\n",
        "\treturn filtered_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZKZBeQspFsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vis_all_feat(data, class_):\n",
        "    for col_ind in range(data.shape[1]):\n",
        "\t\t    print(\"Viewing Feature #{0}\".format(str(col_ind)))\n",
        "\t\t    vis_single_feat(data, class_, col_ind)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAw98DMWqcj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vis_single_feat(data, class_, ind):\n",
        "\t# create graph of classification and feature values\t\n",
        "\tplt.figure(100) # display two plots on separate figures\n",
        "\tdf = pd.DataFrame(data)\n",
        "\tfeat_vals = df.iloc[:, ind]\n",
        "\tplt.scatter(feat_vals, class_)\n",
        "\tplt.title(\"Plot of Feature {0}\".format(str(ind)))\n",
        "\tplt.xlabel(\"Feature Value\")\n",
        "\tplt.ylabel(\"Classification\")\n",
        "\t\n",
        "\t# create bar graph of mean feature values for each classification\n",
        "\tplt.figure(200)\n",
        "\tplt.title(\"Mean Values of Feature {0}\".format(str(ind)))\n",
        "\tplt.xlabel(\"Classification\")\n",
        "\tplt.ylabel(\"Mean Feature Value\")\n",
        "\tmean_df = pd.concat([df.iloc[:, ind], pd.Series(class_)], axis=1)\n",
        "\tmean_df.columns = [\"values\", \"classif\"]\t\n",
        "\tmean_df.groupby(\"classif\", as_index=False)[\"values\"].mean().loc[:,\"values\"].plot(kind='bar')\n",
        "\t\n",
        "\tplt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODDMJv9bufip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_pairplot(data, class_):\n",
        "\tdata_df = pd.DataFrame(data)\n",
        "\t# add classification so the plot can be colored by it\n",
        "\tdata_df.loc[:, \"classif\"] = pd.Series(class_)\n",
        "\tsns.pairplot(data_df, hue='classif')\n",
        "\tplt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnXSQrissgHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fourError(X, Y, model):\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0, stratify=Y)\n",
        "    \n",
        "    Train_x, TrainDev_x, Train_y, TrainDev_y = train_test_split(X_train, Y_train, test_size=0.2, random_state=0, stratify=Y_train)\n",
        "    Dev_x, Test_x, Dev_y, Test_y = train_test_split(X_test, Y_test, test_size=0.5, random_state=0, stratify=Y_test)\n",
        "\n",
        "    model.fit(Train_x, Train_y)\n",
        "\n",
        "    y_true, trainDev_pred = TrainDev_y, model.predict(TrainDev_x)\n",
        "\n",
        "    print(\"Train-Train Dev,   e1:\", metrics.mean_squared_error(TrainDev_y, trainDev_pred),\"\\n\")\n",
        "    print(\"Accuracy: \", 1 - metrics.mean_squared_error(TrainDev_y, trainDev_pred))\n",
        "    print( '\\nClassification report\\n' )\n",
        "    print(classification_report(y_true, trainDev_pred))\n",
        "\n",
        "    y_true, dev_pred = Dev_y, model.predict(Dev_x)\n",
        "    print(\"Train-Dev,   e2\", metrics.mean_squared_error(Dev_y, dev_pred),\"\\n\")\n",
        "    print(\"Accuracy: \", 1 - metrics.mean_squared_error(Dev_y, dev_pred))\n",
        "    print( '\\nClassification report\\n' )\n",
        "    print(classification_report(y_true, dev_pred))\n",
        "\n",
        "    y_true, test_pred = Test_y, model.predict(Test_x)\n",
        "    print(\"Train-Test,   e3: \", metrics.mean_squared_error(Test_y, test_pred),\"\\n\")\n",
        "    print(\"Accuracy: \", 1 - metrics.mean_squared_error(Test_y, test_pred))\n",
        "    print( '\\nClassification report\\n' )\n",
        "    print(classification_report(y_true, test_pred))\n",
        "\n",
        "    y_true, devTest_pred = Y_test, model.predict(X_test)\n",
        "    print(\"Train-(Dev+Test),   e4: \", metrics.mean_squared_error(Y_test, devTest_pred),\"\\n\")\n",
        "    print(\"Accuracy: \", 1 - metrics.mean_squared_error(Y_test, devTest_pred))\n",
        "    print( '\\nClassification report\\n' )\n",
        "    print(classification_report(y_true, devTest_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LJF39VzsYPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def svm(X_train, Y_train, kernel, weight, gamma):\n",
        "\n",
        "    svm = SVC(C=1, kernel=kernel, degree=3, gamma=gamma, coef0=0.0, shrinking=True, \n",
        "          probability=False, tol=0.001, cache_size=200, class_weight=weight,\n",
        "          max_iter=-1, decision_function_shape=\"ovr\", random_state = 0)\n",
        "\n",
        "    #5-Fold\n",
        "    cv_result_svm_5 = cross_val_score(svm, X_train, Y_train, cv=5, scoring='accuracy')\n",
        "  \n",
        "    #10-Fold\n",
        "    cv_result_svm_10 = cross_val_score(svm, X_train, Y_train, cv=10, scoring='accuracy')\n",
        "  \n",
        "    #Random One Holdout\n",
        "    x_train, x_test, y_train, y_test_random = randomOneHoldout(X_train, Y_train)\n",
        "    svm.fit(x_train, y_train)\n",
        "    y_pred_svm_random = svm.predict(x_test)\n",
        "  \n",
        "    #Stratified One Holdout\n",
        "    x_train, x_test, y_train, y_test_stratified = stratifiedOneHoldout(X_train, Y_train)\n",
        "    svm.fit(x_train, y_train)\n",
        "    y_pred_svm_stratified = svm.predict(x_test)\n",
        "\n",
        "    print(\"5 Fold\")\n",
        "    print(\"SVM Accuracy: \", cv_result_svm_5.mean())\n",
        "  \n",
        "    print(\"10 Fold\")\n",
        "    print(\"SVM Accuracy: \", cv_result_svm_10.mean())\n",
        "\n",
        "    print(\"Random One Hold Out\")\n",
        "    print(\"SVM Accuracy: \", 1 - metrics.mean_squared_error(y_test_random, y_pred_svm_random))\n",
        "  \n",
        "    print(\"Stratified One Hold Out Fold\")\n",
        "    print(\"SVM Accuracy: \", 1 - metrics.mean_squared_error(y_test_stratified, y_pred_svm_stratified))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlB4byLoyxyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_forest(X_train, Y_train, forest_size, max_depth, criterion, min_samples_split, class_weight):\n",
        "    rf = RandomForestClassifier(n_estimators=forest_size, oob_score=True, n_jobs=-1, max_depth=max_depth, criterion=criterion, min_samples_split = min_samples_split, class_weight=class_weight, random_state=0)\n",
        "\t\n",
        "\t  #5-Fold\n",
        "    cv_result_rf_5 = cross_val_score(rf, X_train, Y_train, cv=5, scoring='accuracy')\n",
        "  \n",
        "    #10-Fold\n",
        "    cv_result_rf_10 = cross_val_score(rf, X_train, Y_train, cv=10, scoring='accuracy')\n",
        "  \n",
        "    #Random One Holdout\n",
        "    x_train, x_test, y_train, y_test_random = randomOneHoldout(X_train, Y_train)\n",
        "    rf.fit(x_train, y_train)\n",
        "    y_pred_rf_random = rf.predict(x_test)\n",
        "  \n",
        "    #Stratified One Holdout\n",
        "    x_train, x_test, y_train, y_test_stratified = stratifiedOneHoldout(X_train, Y_train)\n",
        "    rf.fit(x_train, y_train)\n",
        "    y_pred_rf_stratified = rf.predict(x_test)\n",
        "\n",
        "    print(\"Stratified One Hold Out Fold\")\n",
        "    print(\"Random Forest  Accuracy: \", 1 - metrics.mean_squared_error(y_test_stratified, y_pred_rf_stratified))\n",
        "\n",
        "    print(\"5 Fold\")\n",
        "    print(\"Random Forest Accuracy: \", cv_result_rf_5.mean())\n",
        "  \n",
        "    print(\"10 Fold\")\n",
        "    print(\"Random Forest  Accuracy: \", cv_result_rf_10.mean())\n",
        "\n",
        "    print(\"Random One Hold Out\")\n",
        "    print(\"Random Forest  Accuracy: \", 1 - metrics.mean_squared_error(y_test_random, y_pred_rf_random))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsopl6QL8jP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tuningDepth(x_train, x_test, y_train, y_test_stratified):\n",
        "\n",
        "    max_depth_range = list(range(1, 10))\n",
        "    max_depth_range.append(str(\"None\"))\n",
        "    \n",
        "    for depth in max_depth_range:\n",
        "        if(depth == \"None\"):\n",
        "            clf = RandomForestClassifier(random_state = 0)\n",
        "            clf.fit(x_train, y_train)\n",
        "        else:  \n",
        "            clf = RandomForestClassifier(max_depth = depth, random_state = 0)\n",
        "            clf.fit(x_train, y_train)\n",
        "\n",
        "        accuracy = clf.score(x_test, y_test_stratified)*100\n",
        "        print(\"Depth: \", depth, \" Accuracy: \", accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJj-M4tm8dZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tuningSplit(x_train, x_test, y_train, y_test_stratified):\n",
        "    criterion = [\"gini\", \"entropy\"]\n",
        "\n",
        "    for i in criterion:\n",
        "        clf = RandomForestClassifier(criterion = i, max_depth = 7, random_state = 0)\n",
        "        clf.fit(x_train, y_train)\n",
        "\n",
        "        accuracy = clf.score(x_test, y_test_stratified)*100\n",
        "        print(\"Criterion: \", i, \"   Accuracy: \", accuracy)\n",
        "\n",
        "    for i in range(2, 10):\n",
        "        clf = RandomForestClassifier(max_depth = 7, min_samples_split = i, random_state = 0)\n",
        "        clf.fit(x_train, y_train)\n",
        "\n",
        "        accuracy = clf.score(x_test, y_test_stratified)*100\n",
        "        print(\"min_samples_split: \", i, \"   Accuracy: \", accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlHEQXZc8dqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tuningClassWeight(x_train, x_test, y_train, y_test_stratified):\n",
        "    # No class weight\n",
        "    clf = RandomForestClassifier(max_depth = 7, random_state = 0)\n",
        "    clf.fit(x_train, y_train)\n",
        "\n",
        "    accuracy = clf.score(x_test, y_test_stratified)*100\n",
        "    print(\"Class weight: None           Accuracy: \", accuracy)\n",
        "\n",
        "    # Balanced class weight\n",
        "    clf = RandomForestClassifier(max_depth = 7, random_state = 0, class_weight ='balanced')\n",
        "    clf.fit(x_train, y_train)\n",
        "\n",
        "    accuracy = clf.score(x_test, y_test_stratified)*100\n",
        "    print(\"Class weight: Balanced       Accuracy: \", accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqBexbvisccC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def AdaBoost(model, n_estimators, learning_rate, X_train, Y_train, X_test, Y_test):\n",
        "    clf = BaggingClassifier(base_estimator = model, n_estimators= n_estimators, learning_rate=learning_rate, random_state=0)\n",
        "    clf.fit(X_train, Y_train)\n",
        "    clf.predict(X_test)\n",
        "    return clf.score(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIDBDP930wQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bagging(model, n_estimators, X_train, Y_train, X_test, Y_test):\n",
        "    clf = AdaBoostClassifier(base_estimator = model, n_estimators= n_estimators, random_state=0)\n",
        "    clf.fit(X_train, Y_train)\n",
        "    clf.predict(X_test)\n",
        "    return clf.score(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUdttb6JsjlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def displayAccuracy(X, Y):\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
        "\n",
        "    kernel = [\"linear\", \"rbf\", \"poly\", \"sigmoid\"]\n",
        "    weight = [None, \"balanced\"]\n",
        "    gamma = [\"auto\", \"scale\"]\n",
        "    \n",
        "    for i in kernel:\n",
        "        for j in weight:\n",
        "            for k in gamma:\n",
        "                if i != \"linear\":\n",
        "                    print(\"Kernel: {} - Weight: {} - Gamma: {}\".format(str(i), j, k))\n",
        "                    svm(X_train, Y_train, i, j, k)\n",
        "                else:\n",
        "                    print(\"Kernel: {} - Weight: {} - Gamma: {}\".format(str(i), j, \"auto\"))\n",
        "                    svm(X_train, Y_train, i, j, k)\n",
        "        print()\n",
        "\n",
        "    combined approach\n",
        "    for depth in max_depth_range:\n",
        "        for c in criterion:\n",
        "            for i in range(2, 10):\n",
        "                for w in weight:\n",
        "                    print(\"Depth: {}, Criterion: {}, Min Split {}, Weight: {}\".format(depth, c, i, w))\n",
        "                    random_forest(X_train, Y_train, 100, depth, c, i, w)\n",
        "        print(\"\\n\")\n",
        "\n",
        "    forest_size = [25, 50, 75, 100, 125, 150, 175, 200]\n",
        "    \n",
        "    for s in forest_size:\n",
        "        random_forest(X_train, Y_train, s, 7, \"entropy\", 3, \"balanced\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVnTGynw2_UY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compareBaseModels(X, Y):\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
        "\n",
        "    svm(X_train, Y_train, \"rbf\", None, \"scale\")\n",
        "    print(\"\")\n",
        "    random_forest(X_train, Y_train, 100, None, \"gini\", 2, None)\n",
        "\n",
        "    x_train, x_test, y_train, y_test_stratified = stratifiedOneHoldout(X_train, Y_train)\n",
        "    #Individual tuning\n",
        "    print(\"\\n\")\n",
        "    tuningDepth(x_train, x_test, y_train, y_test_stratified);\n",
        "    tuningSplit(x_train, x_test, y_train, y_test_stratified)\n",
        "    tuningClassWeight( x_train, x_test, y_train, y_test_stratified)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjci_18qnspz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    breast_cancer = datasets.load_breast_cancer()\n",
        "    X = breast_cancer.data\n",
        "    Y = breast_cancer.target\n",
        "  \n",
        "    #Shape of the data\n",
        "    print(X.shape, end=\"\\n\")\n",
        "\n",
        "    feauture = pd.DataFrame(Y)\n",
        "    df = pd.DataFrame(X)\n",
        "    rf = RandomForestClassifier(n_estimators=100, oob_score=True, n_jobs=-1, max_depth=7, criterion=\"entropy\", min_samples_split = 3, class_weight=\"balanced\", random_state=0)\n",
        "    svm = SVC(C=1, kernel=\"linear\", degree=3, gamma=\"scale\", coef0=0.0, shrinking=True, \n",
        "          probability=True, tol=0.001, cache_size=200, class_weight=None,\n",
        "          max_iter=-1, decision_function_shape=\"ovr\", random_state = 0)\n",
        "    fourError(X, Y, svm)\n",
        "    visulize_class(feauture)\n",
        "    compareBaseModels(X, Y)\n",
        "    displayAccuracy(X, Y)\n",
        "\n",
        "    identify_noise(df)\n",
        "    heat_map(df)\n",
        "    \n",
        "    #filter strongly correlated features - can see which ones in correlation map\n",
        "    X = filter_features(X, [2, 3, 20, 22, 23, 12, 13])\n",
        "\n",
        "    vis_all_feat(X, Y)\n",
        "    X = filter_features(X, [1, 2, 6, 7, 9, 10, 14, 15])\n",
        "    print(\"Cleaned data\")\n",
        "    fourError(X, Y, svm)\n",
        "    #remaining features\n",
        "    plot_pairplot(X, Y)\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ9JddedoQ3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
        "#best model \n",
        "\n",
        "learning_rate = [0.0001, 0.001, 0.01, 0.1, 1 ,2 ,3 ,4, 5]\n",
        "\n",
        "result_ada_2 = []\n",
        "for i in learning_rate: #i -> Learning Rate\n",
        "    x = []\n",
        "    for j in range(50, 150, 25): #j -> N estimators\n",
        "        x.append(AdaBoost(svm, j, i, X_train, Y_train, X_test, Y_test))\n",
        "    result_ada_2.append(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ103mcEqi62",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "379e722b-1cac-4e61-84a3-f993f0f700e8"
      },
      "source": [
        "x = pd.DataFrame(result_ada_2)\n",
        "x"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.952261</td>\n",
              "      <td>0.952261</td>\n",
              "      <td>0.952261</td>\n",
              "      <td>0.952261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.952261</td>\n",
              "      <td>0.952261</td>\n",
              "      <td>0.952261</td>\n",
              "      <td>0.952261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.949749</td>\n",
              "      <td>0.949749</td>\n",
              "      <td>0.949749</td>\n",
              "      <td>0.949749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.939698</td>\n",
              "      <td>0.944724</td>\n",
              "      <td>0.939698</td>\n",
              "      <td>0.927136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.736181</td>\n",
              "      <td>0.695980</td>\n",
              "      <td>0.665829</td>\n",
              "      <td>0.650754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.904523</td>\n",
              "      <td>0.909548</td>\n",
              "      <td>0.904523</td>\n",
              "      <td>0.904523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.894472</td>\n",
              "      <td>0.854271</td>\n",
              "      <td>0.816583</td>\n",
              "      <td>0.796482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.773869</td>\n",
              "      <td>0.726131</td>\n",
              "      <td>0.695980</td>\n",
              "      <td>0.655779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.861809</td>\n",
              "      <td>0.796482</td>\n",
              "      <td>0.736181</td>\n",
              "      <td>0.678392</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3\n",
              "0  0.952261  0.952261  0.952261  0.952261\n",
              "1  0.952261  0.952261  0.952261  0.952261\n",
              "2  0.949749  0.949749  0.949749  0.949749\n",
              "3  0.939698  0.944724  0.939698  0.927136\n",
              "4  0.736181  0.695980  0.665829  0.650754\n",
              "5  0.904523  0.909548  0.904523  0.904523\n",
              "6  0.894472  0.854271  0.816583  0.796482\n",
              "7  0.773869  0.726131  0.695980  0.655779\n",
              "8  0.861809  0.796482  0.736181  0.678392"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-ZsctAW0a7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
        "#best model \n",
        "\n",
        "\n",
        "result_bagging = []\n",
        "for j in range(50, 150, 25): #j -> N estimators\n",
        "    result_bagging.append(bagging(svm, j, X_train, Y_train, X_test, Y_test))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6iPhXfj5GKx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "09672aac-294d-45ec-c2e3-14046d565f7b"
      },
      "source": [
        "y = pd.DataFrame(result_bagging)\n",
        "y"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.736181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.695980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.665829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.650754</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0\n",
              "0  0.736181\n",
              "1  0.695980\n",
              "2  0.665829\n",
              "3  0.650754"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW9vgTj05sb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}